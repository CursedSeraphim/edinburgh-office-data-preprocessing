{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324dc95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this once if the packages are not installed yet\n",
    "# !pip install pillow umap-learn scikit-learn pandas matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7787171",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import glob\n",
    "import tarfile\n",
    "import csv\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import umap\n",
    "from sklearn.manifold import trustworthiness\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "# Matches grayscale  \"1x1\", \"32x18\"\n",
    "# and color pixels   \"1x1_r\", \"1x1_g\", \"1x1_b\"\n",
    "PIXEL_RE = re.compile(r\"^\\d+x\\d+(?:_[rgb])?$\")\n",
    "\n",
    "# Filename pattern for Edinburgh frames\n",
    "FILENAME_RE = re.compile(\n",
    "    r\"inspacecam163_(\\d{4})_(\\d{2})_(\\d{2})_(\\d{2})_(\\d{2})_(\\d{2})\\.jpg$\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e1a056e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_time_from_filename(name):\n",
    "    \"\"\"Returns (hour, minute, second) or None if the filename does not match.\"\"\"\n",
    "    base = os.path.basename(name)\n",
    "    m = FILENAME_RE.match(base)\n",
    "    if not m:\n",
    "        return None\n",
    "    h = int(m.group(4))\n",
    "    m_ = int(m.group(5))\n",
    "    s = int(m.group(6))\n",
    "    return h, m_, s\n",
    "\n",
    "\n",
    "def seconds_since_midnight(h, m, s):\n",
    "    return h * 3600 + m * 60 + s\n",
    "\n",
    "\n",
    "def parse_time_string(s):\n",
    "    \"\"\"\n",
    "    Parse HH:MM or HH:MM:SS -> seconds since midnight.\n",
    "    \"\"\"\n",
    "    parts = s.split(\":\")\n",
    "    if len(parts) == 2:\n",
    "        h, m = parts\n",
    "        s_val = 0\n",
    "    elif len(parts) == 3:\n",
    "        h, m, s_val = parts\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid time format: {s!r}. Expected HH:MM or HH:MM:SS\")\n",
    "    h_i = int(h)\n",
    "    m_i = int(m)\n",
    "    s_i = int(s_val)\n",
    "    if not (0 <= h_i < 24 and 0 <= m_i < 60 and 0 <= s_i < 60):\n",
    "        raise ValueError(f\"Time out of range: {s!r}\")\n",
    "    return seconds_since_midnight(h_i, m_i, s_i)\n",
    "\n",
    "\n",
    "def time_filter(day_sec, start_sec, end_sec, use_all_times):\n",
    "    if use_all_times:\n",
    "        return True\n",
    "    return start_sec <= day_sec <= end_sec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31839fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_tar_files(folder):\n",
    "    pattern = os.path.join(folder, \"day_*.tar\")\n",
    "    tar_paths = sorted(glob.glob(pattern))\n",
    "    if not tar_paths:\n",
    "        raise SystemExit(f\"No tar files matching 'day_*.tar' found in {folder}\")\n",
    "    return tar_paths\n",
    "\n",
    "\n",
    "def first_pass_lengths(tar_paths, start_sec, end_sec, use_all_times, frame_step):\n",
    "    \"\"\"\n",
    "    First pass: determine, for each tar, how many kept frames (after subsampling)\n",
    "    fall into the specified time window (or all times if use_all_times is True).\n",
    "\n",
    "    Returns:\n",
    "      - line_index_by_path: {tar_path -> line_id}\n",
    "      - line_length_by_path: {tar_path -> number_of_kept_frames}\n",
    "      - global_max_step: maximum step index across all lines\n",
    "    \"\"\"\n",
    "    line_index_by_path = {}\n",
    "    line_length_by_path = {}\n",
    "    line_lengths = []\n",
    "\n",
    "    line_counter = 0\n",
    "\n",
    "    for path in tar_paths:\n",
    "        with tarfile.open(path, \"r\") as tar:\n",
    "            times = []\n",
    "            for member in tar.getmembers():\n",
    "                if not member.isfile():\n",
    "                    continue\n",
    "                t = parse_time_from_filename(member.name)\n",
    "                if t is None:\n",
    "                    continue\n",
    "                h, m, s = t\n",
    "                day_sec = seconds_since_midnight(h, m, s)\n",
    "                if time_filter(day_sec, start_sec, end_sec, use_all_times):\n",
    "                    times.append(day_sec)\n",
    "\n",
    "        times.sort()\n",
    "        if times:\n",
    "            kept_len = (len(times) + frame_step - 1) // frame_step\n",
    "            line_index_by_path[path] = line_counter\n",
    "            line_length_by_path[path] = kept_len\n",
    "            line_lengths.append(kept_len)\n",
    "            line_counter += 1\n",
    "\n",
    "    if not line_lengths:\n",
    "        raise SystemExit(\"No frames found in the specified time window.\")\n",
    "\n",
    "    max_len = max(line_lengths)\n",
    "    global_max_step = max_len - 1 if max_len > 1 else 0\n",
    "\n",
    "    return line_index_by_path, line_length_by_path, global_max_step\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f20a5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_header(width, height, grayscale):\n",
    "    header = [\n",
    "        \"id\",\n",
    "        \"line\",\n",
    "        \"label\",\n",
    "        \"step\",\n",
    "        \"daytimestamp\",\n",
    "        \"daytime\",\n",
    "        \"action\",\n",
    "        \"age\",\n",
    "        \"age_global\",\n",
    "    ]\n",
    "    # Pixel columns; grayscale: <x>x<y>\n",
    "    # Color: <x>x<y>_r, <x>x<y>_g, <x>x<y>_b\n",
    "    for x in range(1, width + 1):\n",
    "        for y in range(1, height + 1):\n",
    "            if grayscale:\n",
    "                header.append(f\"{x}x{y}\")\n",
    "            else:\n",
    "                header.append(f\"{x}x{y}_r\")\n",
    "                header.append(f\"{x}x{y}_g\")\n",
    "                header.append(f\"{x}x{y}_b\")\n",
    "    return header\n",
    "\n",
    "\n",
    "def extract_pixels(img_fileobj, width, height, grayscale):\n",
    "    \"\"\"\n",
    "    Open image, convert to target mode and size, and return a flat list of values.\n",
    "    Grayscale: one value per pixel.\n",
    "    Color: three values (R, G, B) per pixel.\n",
    "    \"\"\"\n",
    "    img = Image.open(img_fileobj)\n",
    "    if grayscale:\n",
    "        img = img.convert(\"L\")\n",
    "    else:\n",
    "        img = img.convert(\"RGB\")\n",
    "    img = img.resize((width, height), resample=Image.BILINEAR)\n",
    "\n",
    "    pixels = img.load()\n",
    "    values = []\n",
    "    for x in range(width):         # x = 0..width-1\n",
    "        for y in range(height):    # y = 0..height-1\n",
    "            if grayscale:\n",
    "                values.append(pixels[x, y])\n",
    "            else:\n",
    "                r, g, b = pixels[x, y]\n",
    "                values.extend([r, g, b])\n",
    "    return values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3f707ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def second_pass_write_csv(\n",
    "    tar_paths,\n",
    "    line_index_by_path,\n",
    "    line_length_by_path,\n",
    "    global_max_step,\n",
    "    start_sec,\n",
    "    end_sec,\n",
    "    use_all_times,\n",
    "    frame_step,\n",
    "    width,\n",
    "    height,\n",
    "    grayscale,\n",
    "    output_path,\n",
    "):\n",
    "    header = build_header(width, height, grayscale)\n",
    "    global_id = 0\n",
    "    total_rows = 0\n",
    "\n",
    "    with open(output_path, \"w\", newline=\"\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(header)\n",
    "\n",
    "        for path in tar_paths:\n",
    "            if path not in line_index_by_path:\n",
    "                continue  # no frames in window\n",
    "\n",
    "            line_id = line_index_by_path[path]\n",
    "            line_len = line_length_by_path[path]\n",
    "\n",
    "            frames = []\n",
    "            with tarfile.open(path, \"r\") as tar:\n",
    "                for member in tar.getmembers():\n",
    "                    if not member.isfile():\n",
    "                        continue\n",
    "                    t = parse_time_from_filename(member.name)\n",
    "                    if t is None:\n",
    "                        continue\n",
    "                    h, m, s = t\n",
    "                    day_sec = seconds_since_midnight(h, m, s)\n",
    "                    if not time_filter(day_sec, start_sec, end_sec, use_all_times):\n",
    "                        continue\n",
    "                    time_str = f\"{h:02d}:{m:02d}:{s:02d}\"\n",
    "                    frames.append((day_sec, time_str, member))\n",
    "\n",
    "                frames.sort(key=lambda x: x[0])\n",
    "                frames = frames[::frame_step]\n",
    "\n",
    "                for step, (day_sec, time_str, member) in enumerate(frames):\n",
    "                    if line_len > 1:\n",
    "                        age = step / (line_len - 1)\n",
    "                    else:\n",
    "                        age = 0.0\n",
    "\n",
    "                    if global_max_step > 0:\n",
    "                        age_global = step / global_max_step\n",
    "                    else:\n",
    "                        age_global = 0.0\n",
    "\n",
    "                    img_fileobj = tar.extractfile(member)\n",
    "                    if img_fileobj is None:\n",
    "                        continue\n",
    "\n",
    "                    pixel_values = extract_pixels(\n",
    "                        img_fileobj,\n",
    "                        width=width,\n",
    "                        height=height,\n",
    "                        grayscale=grayscale,\n",
    "                    )\n",
    "\n",
    "                    row = [\n",
    "                        global_id,          # id\n",
    "                        line_id,            # line (trajectory/day id)\n",
    "                        \"\",                 # label\n",
    "                        step,               # step\n",
    "                        day_sec,            # daytimestamp\n",
    "                        time_str,           # daytime\n",
    "                        \"\",                 # action\n",
    "                        f\"{age:.6f}\",       # age\n",
    "                        f\"{age_global:.6f}\" # age_global\n",
    "                    ] + pixel_values\n",
    "\n",
    "                    writer.writerow(row)\n",
    "                    global_id += 1\n",
    "                    total_rows += 1\n",
    "\n",
    "    print(f\"Wrote {total_rows} rows to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4cb2aaea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_trajectory_filename(\n",
    "    output_dir,\n",
    "    width,\n",
    "    height,\n",
    "    grayscale,\n",
    "    use_all_times,\n",
    "    start_time,\n",
    "    end_time,\n",
    "    frame_step,\n",
    "):\n",
    "    \"\"\"\n",
    "    Create a unique filename for trajectories based on key parameters.\n",
    "    \"\"\"\n",
    "    mode = \"gray\" if grayscale else \"rgb\"\n",
    "    if use_all_times:\n",
    "        tw = \"all\"\n",
    "    else:\n",
    "        tw = f\"{start_time.replace(':','')}-{end_time.replace(':','')}\"\n",
    "    name = f\"trajectories_w{width}h{height}_{mode}_tw{tw}_step{frame_step}.csv\"\n",
    "    return os.path.join(output_dir, name)\n",
    "\n",
    "\n",
    "def build_trajectories_csv(\n",
    "    folder,\n",
    "    output_dir=\".\",\n",
    "    output_path=None,\n",
    "    width=128,\n",
    "    height=72,\n",
    "    grayscale=True,\n",
    "    start_time=\"15:00:00\",\n",
    "    end_time=\"15:06:59\",\n",
    "    use_all_times=False,\n",
    "    frame_step=1,\n",
    "):\n",
    "    \"\"\"\n",
    "    Build trajectory CSV from Edinburgh office monitoring tar files.\n",
    "\n",
    "    Each row = one frame (downsampled image).\n",
    "    'line' encodes the day/trajectory id, 'step' encodes the time order within line.\n",
    "\n",
    "    If output_path is None, a unique filename is generated from parameters.\n",
    "    \"\"\"\n",
    "    if frame_step <= 0:\n",
    "        raise ValueError(\"frame_step must be >= 1\")\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    if output_path is None:\n",
    "        output_path = make_trajectory_filename(\n",
    "            output_dir=output_dir,\n",
    "            width=width,\n",
    "            height=height,\n",
    "            grayscale=grayscale,\n",
    "            use_all_times=use_all_times,\n",
    "            start_time=start_time,\n",
    "            end_time=end_time,\n",
    "            frame_step=frame_step,\n",
    "        )\n",
    "    else:\n",
    "        out_dir = os.path.dirname(output_path)\n",
    "        if out_dir:\n",
    "            os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "    tar_paths = list_tar_files(folder)\n",
    "\n",
    "    if use_all_times:\n",
    "        start_sec = 0\n",
    "        end_sec = 24 * 3600 - 1\n",
    "    else:\n",
    "        start_sec = parse_time_string(start_time)\n",
    "        end_sec = parse_time_string(end_time)\n",
    "        if end_sec < start_sec:\n",
    "            raise ValueError(\"end_time must be >= start_time\")\n",
    "\n",
    "    (\n",
    "        line_index_by_path,\n",
    "        line_length_by_path,\n",
    "        global_max_step,\n",
    "    ) = first_pass_lengths(\n",
    "        tar_paths,\n",
    "        start_sec,\n",
    "        end_sec,\n",
    "        use_all_times,\n",
    "        frame_step,\n",
    "    )\n",
    "\n",
    "    print(f\"Found {len(line_index_by_path)} trajectories (days)\")\n",
    "\n",
    "    second_pass_write_csv(\n",
    "        tar_paths,\n",
    "        line_index_by_path,\n",
    "        line_length_by_path,\n",
    "        global_max_step,\n",
    "        start_sec,\n",
    "        end_sec,\n",
    "        use_all_times,\n",
    "        frame_step,\n",
    "        width,\n",
    "        height,\n",
    "        grayscale,\n",
    "        output_path,\n",
    "    )\n",
    "\n",
    "    return output_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e0208e",
   "metadata": {},
   "outputs": [
    {
     "ename": "SystemExit",
     "evalue": "No tar files matching 'day_*.tar' found in /path/to/edinburgh_tars",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m No tar files matching 'day_*.tar' found in /path/to/edinburgh_tars\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Christian\\miniconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3585: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "# === GLOBAL CONFIG ===\n",
    "SEED = 42  # used for sampling + UMAP\n",
    "\n",
    "edinburgh_folder = \".\"   # <- adjust this path\n",
    "trajectories_output_dir = \"trajectories\"      # where trajectory CSVs go\n",
    "embeddings_output_dir   = \"embeddings\"        # where .npy embeddings and plots go\n",
    "\n",
    "# Time window / resolution settings\n",
    "width = 128\n",
    "height = 72\n",
    "grayscale = True       # False = keep RGB\n",
    "use_all_times = False  # True = ignore time window\n",
    "start_time = \"15:00:00\"\n",
    "end_time   = \"15:06:59\"\n",
    "frame_step = 1         # 10 = one frame every 10 frames, etc.\n",
    "\n",
    "os.makedirs(trajectories_output_dir, exist_ok=True)\n",
    "os.makedirs(embeddings_output_dir, exist_ok=True)\n",
    "\n",
    "# Build trajectories CSV (auto-named based on parameters)\n",
    "traj_csv_path = build_trajectories_csv(\n",
    "    folder=edinburgh_folder,\n",
    "    output_dir=trajectories_output_dir,\n",
    "    width=width,\n",
    "    height=height,\n",
    "    grayscale=grayscale,\n",
    "    start_time=start_time,\n",
    "    end_time=end_time,\n",
    "    use_all_times=use_all_times,\n",
    "    frame_step=frame_step,\n",
    ")\n",
    "\n",
    "print(\"Trajectory CSV ready:\", traj_csv_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c980de",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(traj_csv_path)\n",
    "print(\"Full dataframe shape:\", df.shape)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c6d499",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_pixel_columns(df: pd.DataFrame):\n",
    "    pixel_cols = [c for c in df.columns if PIXEL_RE.match(c)]\n",
    "    if not pixel_cols:\n",
    "        raise SystemExit(\n",
    "            \"No pixel columns found. Expected columns like '1x1', '1x2', \"\n",
    "            \"'1x1_r', etc.\"\n",
    "        )\n",
    "    return pixel_cols\n",
    "\n",
    "\n",
    "def sample_frames(df: pd.DataFrame, max_samples=None, random_state=0):\n",
    "    \"\"\"\n",
    "    Optional subsampling for UMAP experiments, to keep runs interactive.\n",
    "    \"\"\"\n",
    "    if max_samples is not None and len(df) > max_samples:\n",
    "        return (\n",
    "            df.sample(n=max_samples, random_state=random_state)\n",
    "            .sort_values([\"line\", \"step\"])\n",
    "            .reset_index(drop=True)\n",
    "        )\n",
    "    return df.reset_index(drop=True)\n",
    "\n",
    "\n",
    "# Example: work on a subset for quick experimentation\n",
    "max_samples = 8000   # or None for all\n",
    "df_sub = sample_frames(df, max_samples=max_samples, random_state=SEED)\n",
    "\n",
    "pixel_cols = find_pixel_columns(df_sub)\n",
    "X = df_sub[pixel_cols].to_numpy(dtype=np.float32)\n",
    "\n",
    "print(\"Subsampled frames:\", len(df_sub))\n",
    "print(\"Pixel dim:\", X.shape[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd60b4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_quality_metrics(X_high, X_low, n_neighbors=15):\n",
    "    \"\"\"\n",
    "    Compute simple projection quality metrics:\n",
    "      - trustworthiness\n",
    "      - kNN overlap (Jaccard over neighbor sets)\n",
    "    \"\"\"\n",
    "    n_samples = X_high.shape[0]\n",
    "    if n_samples <= 1:\n",
    "        return {\"trustworthiness\": np.nan, \"knn_overlap\": np.nan}\n",
    "\n",
    "    k = min(n_neighbors, n_samples - 1)\n",
    "\n",
    "    # Trustworthiness (sklearn implementation)\n",
    "    tw = trustworthiness(X_high, X_low, n_neighbors=k)\n",
    "\n",
    "    # kNN overlap\n",
    "    nn_high = NearestNeighbors(n_neighbors=k + 1, metric=\"euclidean\").fit(X_high)\n",
    "    nn_low = NearestNeighbors(n_neighbors=k + 1, metric=\"euclidean\").fit(X_low)\n",
    "\n",
    "    _, idx_high = nn_high.kneighbors(X_high)\n",
    "    _, idx_low = nn_low.kneighbors(X_low)\n",
    "\n",
    "    overlaps = []\n",
    "    for i in range(n_samples):\n",
    "        hi = set(idx_high[i, 1:])  # drop self\n",
    "        lo = set(idx_low[i, 1:])\n",
    "        inter = len(hi & lo)\n",
    "        union = len(hi | lo)\n",
    "        if union > 0:\n",
    "            overlaps.append(inter / union)\n",
    "\n",
    "    knn_overlap = float(np.mean(overlaps)) if overlaps else np.nan\n",
    "\n",
    "    return {\n",
    "        \"trustworthiness\": float(tw),\n",
    "        \"knn_overlap\": knn_overlap,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee931970",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_embedding_filename(\n",
    "    output_dir,\n",
    "    traj_csv_path,\n",
    "    seed,\n",
    "    n_neighbors,\n",
    "    min_dist,\n",
    "    metric,\n",
    "    n_samples,\n",
    "):\n",
    "    \"\"\"\n",
    "    Create a unique filename for an embedding based on:\n",
    "    - base trajectory CSV\n",
    "    - sample count\n",
    "    - UMAP params\n",
    "    - seed\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    base_traj = os.path.splitext(os.path.basename(traj_csv_path))[0]\n",
    "    md_str = str(min_dist).replace(\".\", \"p\")\n",
    "    metric_str = metric.replace(\" \", \"_\")\n",
    "    name = (\n",
    "        f\"{base_traj}_samples{n_samples}_metric{metric_str}\"\n",
    "        f\"_nn{n_neighbors}_md{md_str}_seed{seed}.npy\"\n",
    "    )\n",
    "    return os.path.join(output_dir, name)\n",
    "\n",
    "\n",
    "def run_umap_grid(\n",
    "    X,\n",
    "    n_neighbors_list,\n",
    "    min_dist_list,\n",
    "    metric,\n",
    "    random_state,\n",
    "    quality_k,\n",
    "    traj_csv_path,\n",
    "    embeddings_dir,\n",
    "):\n",
    "    \"\"\"\n",
    "    Run UMAP for all (n_neighbors, min_dist) combinations.\n",
    "\n",
    "    For each combo:\n",
    "      - tries to load an existing embedding from disk (based on params + seed)\n",
    "      - otherwise runs UMAP, saves the embedding to .npy, and records metrics.\n",
    "\n",
    "    Returns:\n",
    "      - results_df: one row per combo with metrics\n",
    "      - embeddings: {(n_neighbors, min_dist) -> (N, 2) array}\n",
    "    \"\"\"\n",
    "    os.makedirs(embeddings_dir, exist_ok=True)\n",
    "\n",
    "    results = []\n",
    "    embeddings = {}\n",
    "    n_samples = X.shape[0]\n",
    "\n",
    "    for nn in n_neighbors_list:\n",
    "        for md in min_dist_list:\n",
    "            emb_path = make_embedding_filename(\n",
    "                output_dir=embeddings_dir,\n",
    "                traj_csv_path=traj_csv_path,\n",
    "                seed=random_state,\n",
    "                n_neighbors=nn,\n",
    "                min_dist=md,\n",
    "                metric=metric,\n",
    "                n_samples=n_samples,\n",
    "            )\n",
    "\n",
    "            if os.path.exists(emb_path):\n",
    "                print(f\"[CACHE] Loading embedding from {emb_path}\")\n",
    "                emb = np.load(emb_path)\n",
    "            else:\n",
    "                print(f\"[UMAP] n_neighbors={nn}, min_dist={md} (seed={random_state})\")\n",
    "                reducer = umap.UMAP(\n",
    "                    n_neighbors=nn,\n",
    "                    min_dist=md,\n",
    "                    metric=metric,\n",
    "                    n_components=2,\n",
    "                    random_state=random_state,\n",
    "                )\n",
    "                emb = reducer.fit_transform(X)\n",
    "                np.save(emb_path, emb)\n",
    "                print(f\"[SAVE] Stored embedding to {emb_path}\")\n",
    "\n",
    "            metrics = compute_quality_metrics(X, emb, n_neighbors=quality_k)\n",
    "\n",
    "            embeddings[(nn, md)] = emb\n",
    "            row = {\n",
    "                \"n_neighbors\": nn,\n",
    "                \"min_dist\": md,\n",
    "                \"metric\": metric,\n",
    "                \"seed\": random_state,\n",
    "                \"trustworthiness\": metrics[\"trustworthiness\"],\n",
    "                \"knn_overlap\": metrics[\"knn_overlap\"],\n",
    "                \"embedding_path\": emb_path,\n",
    "            }\n",
    "            results.append(row)\n",
    "\n",
    "    results_df = pd.DataFrame(results)\n",
    "    return results_df, embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e1bab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the hyperparameter grid\n",
    "n_neighbors_list = [5, 15, 50]\n",
    "min_dist_list    = [0.0, 0.1, 0.5]\n",
    "\n",
    "metric    = \"euclidean\"\n",
    "quality_k = 15\n",
    "\n",
    "results_df, embeddings = run_umap_grid(\n",
    "    X,\n",
    "    n_neighbors_list=n_neighbors_list,\n",
    "    min_dist_list=min_dist_list,\n",
    "    metric=metric,\n",
    "    random_state=SEED,\n",
    "    quality_k=quality_k,\n",
    "    traj_csv_path=traj_csv_path,\n",
    "    embeddings_dir=embeddings_output_dir,\n",
    ")\n",
    "\n",
    "# Sort by trustworthiness (descending) for quick inspection\n",
    "results_df_sorted = results_df.sort_values(\"trustworthiness\", ascending=False)\n",
    "results_df_sorted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba3f5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_embedding_grid(\n",
    "    df_sub,\n",
    "    embeddings,\n",
    "    results_df,\n",
    "    n_neighbors_list,\n",
    "    min_dist_list,\n",
    "    figsize_scale=4,\n",
    "    plot_path=None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Create a grid of scatterplots:\n",
    "    rows   = different n_neighbors\n",
    "    columns= different min_dist\n",
    "    \"\"\"\n",
    "    if \"line\" not in df_sub.columns:\n",
    "        raise SystemExit(\"Column 'line' not found in dataframe; needed for coloring.\")\n",
    "\n",
    "    cat = pd.Categorical(df_sub[\"line\"])\n",
    "    codes = cat.codes  # 0..K-1\n",
    "\n",
    "    n_rows = len(n_neighbors_list)\n",
    "    n_cols = len(min_dist_list)\n",
    "\n",
    "    fig, axes = plt.subplots(\n",
    "        n_rows,\n",
    "        n_cols,\n",
    "        figsize=(figsize_scale * n_cols, figsize_scale * n_rows),\n",
    "        squeeze=False,\n",
    "    )\n",
    "\n",
    "    for i, nn in enumerate(n_neighbors_list):\n",
    "        for j, md in enumerate(min_dist_list):\n",
    "            ax = axes[i, j]\n",
    "            key = (nn, md)\n",
    "            if key not in embeddings:\n",
    "                ax.axis(\"off\")\n",
    "                continue\n",
    "\n",
    "            emb = embeddings[key]\n",
    "            sc = ax.scatter(\n",
    "                emb[:, 0],\n",
    "                emb[:, 1],\n",
    "                c=codes,\n",
    "                s=3,\n",
    "                alpha=0.7,\n",
    "                cmap=\"tab20\",\n",
    "            )\n",
    "            ax.set_xticks([])\n",
    "            ax.set_yticks([])\n",
    "\n",
    "            match = results_df[\n",
    "                (results_df[\"n_neighbors\"] == nn)\n",
    "                & (results_df[\"min_dist\"] == md)\n",
    "            ]\n",
    "            if not match.empty:\n",
    "                row = match.iloc[0]\n",
    "                title = (\n",
    "                    f\"nn={nn}, md={md}\\n\"\n",
    "                    f\"trust={row['trustworthiness']:.3f}, \"\n",
    "                    f\"kNNov={row['knn_overlap']:.3f}\"\n",
    "                )\n",
    "            else:\n",
    "                title = f\"nn={nn}, md={md}\"\n",
    "            ax.set_title(title, fontsize=9)\n",
    "\n",
    "    fig.tight_layout()\n",
    "\n",
    "    if plot_path is not None:\n",
    "        fig.savefig(plot_path, dpi=300)\n",
    "\n",
    "    return fig\n",
    "\n",
    "\n",
    "base_traj = os.path.splitext(os.path.basename(traj_csv_path))[0]\n",
    "grid_plot_path = os.path.join(\n",
    "    embeddings_output_dir,\n",
    "    f\"{base_traj}_umap_grid_seed{SEED}.png\",\n",
    ")\n",
    "\n",
    "fig = plot_embedding_grid(\n",
    "    df_sub=df_sub,\n",
    "    embeddings=embeddings,\n",
    "    results_df=results_df,\n",
    "    n_neighbors_list=n_neighbors_list,\n",
    "    min_dist_list=min_dist_list,\n",
    "    figsize_scale=4,\n",
    "    plot_path=grid_plot_path,\n",
    ")\n",
    "\n",
    "print(\"Saved grid plot to:\", grid_plot_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9e3628",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick the best config by trustworthiness\n",
    "best = results_df.sort_values(\"trustworthiness\", ascending=False).iloc[0]\n",
    "best_key = (int(best[\"n_neighbors\"]), float(best[\"min_dist\"]))\n",
    "best_emb = embeddings[best_key]\n",
    "\n",
    "print(\"Best config:\", best_key)\n",
    "print(\"trustworthiness =\", best[\"trustworthiness\"], \"kNN overlap =\", best[\"knn_overlap\"])\n",
    "\n",
    "# Attach best embedding as x,y to df_sub and save\n",
    "df_sub_best = df_sub.copy()\n",
    "df_sub_best[\"x\"] = best_emb[:, 0]\n",
    "df_sub_best[\"y\"] = best_emb[:, 1]\n",
    "\n",
    "base_traj = os.path.splitext(os.path.basename(traj_csv_path))[0]\n",
    "best_subset_path = os.path.join(\n",
    "    embeddings_output_dir,\n",
    "    f\"{base_traj}_best_umap_subset_seed{SEED}.csv\",\n",
    ")\n",
    "\n",
    "df_sub_best.to_csv(best_subset_path, index=False)\n",
    "print(\"Saved best subset with embedding to:\", best_subset_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
