{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324dc95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this once if the packages are not installed yet\n",
    "# !pip install pillow umap-learn scikit-learn pandas matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7787171",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import glob\n",
    "import tarfile\n",
    "import csv\n",
    "import math\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import umap\n",
    "from sklearn.manifold import trustworthiness\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "# Matches grayscale  \"1x1\", \"32x18\"\n",
    "# and color pixels   \"1x1_r\", \"1x1_g\", \"1x1_b\"\n",
    "PIXEL_RE = re.compile(r\"^\\d+x\\d+(?:_[rgb])?$\")\n",
    "\n",
    "# Filename pattern for Edinburgh frames\n",
    "FILENAME_RE = re.compile(\n",
    "    r\"inspacecam163_(\\d{4})_(\\d{2})_(\\d{2})_(\\d{2})_(\\d{2})_(\\d{2})\\.jpg$\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1a056e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_time_from_filename(name):\n",
    "    \"\"\"Returns (hour, minute, second) or None if the filename does not match.\"\"\"\n",
    "    base = os.path.basename(name)\n",
    "    m = FILENAME_RE.match(base)\n",
    "    if not m:\n",
    "        return None\n",
    "    h = int(m.group(4))\n",
    "    m_ = int(m.group(5))\n",
    "    s = int(m.group(6))\n",
    "    return h, m_, s\n",
    "\n",
    "\n",
    "def seconds_since_midnight(h, m, s):\n",
    "    return h * 3600 + m * 60 + s\n",
    "\n",
    "\n",
    "def parse_time_string(s):\n",
    "    \"\"\"\n",
    "    Parse HH:MM or HH:MM:SS -> seconds since midnight.\n",
    "    \"\"\"\n",
    "    parts = s.split(\":\")\n",
    "    if len(parts) == 2:\n",
    "        h, m = parts\n",
    "        s_val = 0\n",
    "    elif len(parts) == 3:\n",
    "        h, m, s_val = parts\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid time format: {s!r}. Expected HH:MM or HH:MM:SS\")\n",
    "    h_i = int(h)\n",
    "    m_i = int(m)\n",
    "    s_i = int(s_val)\n",
    "    if not (0 <= h_i < 24 and 0 <= m_i < 60 and 0 <= s_i < 60):\n",
    "        raise ValueError(f\"Time out of range: {s!r}\")\n",
    "    return seconds_since_midnight(h_i, m_i, s_i)\n",
    "\n",
    "\n",
    "def time_filter(day_sec, start_sec, end_sec, use_all_times):\n",
    "    if use_all_times:\n",
    "        return True\n",
    "    return start_sec <= day_sec <= end_sec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31839fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_tar_files(folder):\n",
    "    pattern = os.path.join(folder, \"day_*.tar\")\n",
    "    tar_paths = sorted(glob.glob(pattern))\n",
    "    if not tar_paths:\n",
    "        raise SystemExit(f\"No tar files matching 'day_*.tar' found in {folder}\")\n",
    "    return tar_paths\n",
    "\n",
    "\n",
    "def first_pass_lengths(tar_paths, start_sec, end_sec, use_all_times, frame_step):\n",
    "    \"\"\"\n",
    "    First pass: determine, for each tar, how many kept frames (after subsampling)\n",
    "    fall into the specified time window (or all times if use_all_times is True).\n",
    "\n",
    "    Returns:\n",
    "      - line_index_by_path: {tar_path -> line_id}\n",
    "      - line_length_by_path: {tar_path -> number_of_kept_frames}\n",
    "      - global_max_step: maximum step index across all lines\n",
    "    \"\"\"\n",
    "    line_index_by_path = {}\n",
    "    line_length_by_path = {}\n",
    "    line_lengths = []\n",
    "\n",
    "    line_counter = 0\n",
    "\n",
    "    for path in tar_paths:\n",
    "        with tarfile.open(path, \"r\") as tar:\n",
    "            times = []\n",
    "            for member in tar.getmembers():\n",
    "                if not member.isfile():\n",
    "                    continue\n",
    "                t = parse_time_from_filename(member.name)\n",
    "                if t is None:\n",
    "                    continue\n",
    "                h, m, s = t\n",
    "                day_sec = seconds_since_midnight(h, m, s)\n",
    "                if time_filter(day_sec, start_sec, end_sec, use_all_times):\n",
    "                    times.append(day_sec)\n",
    "\n",
    "        times.sort()\n",
    "        if times:\n",
    "            kept_len = (len(times) + frame_step - 1) // frame_step\n",
    "            line_index_by_path[path] = line_counter\n",
    "            line_length_by_path[path] = kept_len\n",
    "            line_lengths.append(kept_len)\n",
    "            line_counter += 1\n",
    "\n",
    "    if not line_lengths:\n",
    "        raise SystemExit(\"No frames found in the specified time window.\")\n",
    "\n",
    "    max_len = max(line_lengths)\n",
    "    global_max_step = max_len - 1 if max_len > 1 else 0\n",
    "\n",
    "    return line_index_by_path, line_length_by_path, global_max_step\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f20a5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_header(width, height, grayscale):\n",
    "    header = [\n",
    "        \"id\",\n",
    "        \"line\",\n",
    "        \"label\",\n",
    "        \"step\",\n",
    "        \"daytimestamp\",\n",
    "        \"daytime\",\n",
    "        \"action\",\n",
    "        \"age\",\n",
    "        \"age_global\",\n",
    "    ]\n",
    "    # Pixel columns; grayscale: <x>x<y>\n",
    "    # Color: <x>x<y>_r, <x>x<y>_g, <x>x<y>_b\n",
    "    for x in range(1, width + 1):\n",
    "        for y in range(1, height + 1):\n",
    "            if grayscale:\n",
    "                header.append(f\"{x}x{y}\")\n",
    "            else:\n",
    "                header.append(f\"{x}x{y}_r\")\n",
    "                header.append(f\"{x}x{y}_g\")\n",
    "                header.append(f\"{x}x{y}_b\")\n",
    "    return header\n",
    "\n",
    "\n",
    "def extract_pixels(img_fileobj, width, height, grayscale):\n",
    "    \"\"\"\n",
    "    Open image, convert to target mode and size, and return a flat list of values.\n",
    "    Grayscale: one value per pixel.\n",
    "    Color: three values (R, G, B) per pixel.\n",
    "    \"\"\"\n",
    "    img = Image.open(img_fileobj)\n",
    "    if grayscale:\n",
    "        img = img.convert(\"L\")\n",
    "    else:\n",
    "        img = img.convert(\"RGB\")\n",
    "    img = img.resize((width, height), resample=Image.BILINEAR)\n",
    "\n",
    "    pixels = img.load()\n",
    "    values = []\n",
    "    for x in range(width):         # x = 0..width-1\n",
    "        for y in range(height):    # y = 0..height-1\n",
    "            if grayscale:\n",
    "                values.append(pixels[x, y])\n",
    "            else:\n",
    "                r, g, b = pixels[x, y]\n",
    "                values.extend([r, g, b])\n",
    "    return values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f707ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def second_pass_write_csv(\n",
    "    tar_paths,\n",
    "    line_index_by_path,\n",
    "    line_length_by_path,\n",
    "    global_max_step,\n",
    "    start_sec,\n",
    "    end_sec,\n",
    "    use_all_times,\n",
    "    frame_step,\n",
    "    width,\n",
    "    height,\n",
    "    grayscale,\n",
    "    output_path,\n",
    "):\n",
    "    header = build_header(width, height, grayscale)\n",
    "    global_id = 0\n",
    "    total_rows = 0\n",
    "\n",
    "    with open(output_path, \"w\", newline=\"\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(header)\n",
    "\n",
    "        for path in tar_paths:\n",
    "            if path not in line_index_by_path:\n",
    "                continue  # no frames in window\n",
    "\n",
    "            line_id = line_index_by_path[path]\n",
    "            line_len = line_length_by_path[path]\n",
    "\n",
    "            frames = []\n",
    "            with tarfile.open(path, \"r\") as tar:\n",
    "                for member in tar.getmembers():\n",
    "                    if not member.isfile():\n",
    "                        continue\n",
    "                    t = parse_time_from_filename(member.name)\n",
    "                    if t is None:\n",
    "                        continue\n",
    "                    h, m, s = t\n",
    "                    day_sec = seconds_since_midnight(h, m, s)\n",
    "                    if not time_filter(day_sec, start_sec, end_sec, use_all_times):\n",
    "                        continue\n",
    "                    time_str = f\"{h:02d}:{m:02d}:{s:02d}\"\n",
    "                    frames.append((day_sec, time_str, member))\n",
    "\n",
    "                frames.sort(key=lambda x: x[0])\n",
    "                frames = frames[::frame_step]\n",
    "\n",
    "                for step, (day_sec, time_str, member) in enumerate(frames):\n",
    "                    if line_len > 1:\n",
    "                        age = step / (line_len - 1)\n",
    "                    else:\n",
    "                        age = 0.0\n",
    "\n",
    "                    if global_max_step > 0:\n",
    "                        age_global = step / global_max_step\n",
    "                    else:\n",
    "                        age_global = 0.0\n",
    "\n",
    "                    img_fileobj = tar.extractfile(member)\n",
    "                    if img_fileobj is None:\n",
    "                        continue\n",
    "\n",
    "                    pixel_values = extract_pixels(\n",
    "                        img_fileobj,\n",
    "                        width=width,\n",
    "                        height=height,\n",
    "                        grayscale=grayscale,\n",
    "                    )\n",
    "\n",
    "                    row = [\n",
    "                        global_id,          # id\n",
    "                        line_id,            # line (trajectory/day id)\n",
    "                        \"\",                 # label\n",
    "                        step,               # step\n",
    "                        day_sec,            # daytimestamp\n",
    "                        time_str,           # daytime\n",
    "                        \"\",                 # action\n",
    "                        f\"{age:.6f}\",       # age\n",
    "                        f\"{age_global:.6f}\" # age_global\n",
    "                    ] + pixel_values\n",
    "\n",
    "                    writer.writerow(row)\n",
    "                    global_id += 1\n",
    "                    total_rows += 1\n",
    "\n",
    "    print(f\"Wrote {total_rows} rows to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb2aaea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_trajectory_filename(\n",
    "    output_dir,\n",
    "    width,\n",
    "    height,\n",
    "    grayscale,\n",
    "    use_all_times,\n",
    "    start_time,\n",
    "    end_time,\n",
    "    frame_step,\n",
    "):\n",
    "    \"\"\"\n",
    "    Create a unique filename for trajectories based on key parameters.\n",
    "    \"\"\"\n",
    "    mode = \"gray\" if grayscale else \"rgb\"\n",
    "    if use_all_times:\n",
    "        tw = \"all\"\n",
    "    else:\n",
    "        tw = f\"{start_time.replace(':','')}-{end_time.replace(':','')}\"\n",
    "    name = f\"trajectories_w{width}h{height}_{mode}_tw{tw}_step{frame_step}.csv\"\n",
    "    return os.path.join(output_dir, name)\n",
    "\n",
    "\n",
    "def build_trajectories_csv(\n",
    "    folder,\n",
    "    output_dir=\".\",\n",
    "    output_path=None,\n",
    "    width=128,\n",
    "    height=72,\n",
    "    grayscale=True,\n",
    "    start_time=\"15:00:00\",\n",
    "    end_time=\"15:06:59\",\n",
    "    use_all_times=False,\n",
    "    frame_step=1,\n",
    "    target_max_samples=None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Build trajectory CSV from Edinburgh office monitoring tar files.\n",
    "\n",
    "    Each row = one frame (downsampled image).\n",
    "    'line' encodes the day/trajectory id, 'step' encodes the time order within line.\n",
    "\n",
    "    If target_max_samples is given (>0) and frame_step == 1,\n",
    "    frame_step is chosen automatically so that total kept frames\n",
    "    are <= target_max_samples (uniform subsampling in time).\n",
    "    \"\"\"\n",
    "    if frame_step <= 0:\n",
    "        raise ValueError(\"frame_step must be >= 1\")\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    tar_paths = list_tar_files(folder)\n",
    "\n",
    "    if use_all_times:\n",
    "        start_sec = 0\n",
    "        end_sec = 24 * 3600 - 1\n",
    "    else:\n",
    "        start_sec = parse_time_string(start_time)\n",
    "        end_sec = parse_time_string(end_time)\n",
    "        if end_sec < start_sec:\n",
    "            raise ValueError(\"end_time must be >= start_time\")\n",
    "\n",
    "    # Auto-determine frame_step from target_max_samples (no randomness)\n",
    "    if target_max_samples is not None and target_max_samples > 0 and frame_step == 1:\n",
    "        # First pass with frame_step=1 to get total frame count\n",
    "        _, line_length_by_path_full, _ = first_pass_lengths(\n",
    "            tar_paths,\n",
    "            start_sec,\n",
    "            end_sec,\n",
    "            use_all_times,\n",
    "            frame_step=1,\n",
    "        )\n",
    "        total_frames = sum(line_length_by_path_full.values())\n",
    "        if total_frames == 0:\n",
    "            raise SystemExit(\"No frames found in the specified time window.\")\n",
    "\n",
    "        auto_step = max(1, math.ceil(total_frames / target_max_samples))\n",
    "        frame_step = auto_step\n",
    "\n",
    "        print(\n",
    "            f\"Auto frame_step={frame_step} based on target_max_samples={target_max_samples} \"\n",
    "            f\"(total base frames={total_frames}, \"\n",
    "            f\"approx kept={math.ceil(total_frames / frame_step)})\"\n",
    "        )\n",
    "\n",
    "    # Decide output filename (includes final frame_step)\n",
    "    if output_path is None:\n",
    "        output_path = make_trajectory_filename(\n",
    "            output_dir=output_dir,\n",
    "            width=width,\n",
    "            height=height,\n",
    "            grayscale=grayscale,\n",
    "            use_all_times=use_all_times,\n",
    "            start_time=start_time,\n",
    "            end_time=end_time,\n",
    "            frame_step=frame_step,\n",
    "        )\n",
    "    else:\n",
    "        out_dir = os.path.dirname(output_path)\n",
    "        if out_dir:\n",
    "            os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "    (\n",
    "        line_index_by_path,\n",
    "        line_length_by_path,\n",
    "        global_max_step,\n",
    "    ) = first_pass_lengths(\n",
    "        tar_paths,\n",
    "        start_sec,\n",
    "        end_sec,\n",
    "        use_all_times,\n",
    "        frame_step,\n",
    "    )\n",
    "\n",
    "    print(f\"Found {len(line_index_by_path)} trajectories (days)\")\n",
    "    print(\n",
    "        f\"Total kept frames={sum(line_length_by_path.values())} \"\n",
    "        f\"with frame_step={frame_step}\"\n",
    "    )\n",
    "\n",
    "    second_pass_write_csv(\n",
    "        tar_paths,\n",
    "        line_index_by_path,\n",
    "        line_length_by_path,\n",
    "        global_max_step,\n",
    "        start_sec,\n",
    "        end_sec,\n",
    "        use_all_times,\n",
    "        frame_step,\n",
    "        width,\n",
    "        height,\n",
    "        grayscale,\n",
    "        output_path,\n",
    "    )\n",
    "\n",
    "    return output_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e0208e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === GLOBAL CONFIG ===\n",
    "SEED = 0  # used for UMAP and any deterministic operations\n",
    "\n",
    "edinburgh_folder = \".\"   # <- adjust this path\n",
    "trajectories_output_dir = \"trajectories\"\n",
    "embeddings_output_dir   = \"embeddings\"\n",
    "\n",
    "# Time window / resolution settings\n",
    "width = 128\n",
    "height = 72\n",
    "grayscale = True       # False = keep RGB\n",
    "use_all_times = False  # True = ignore time window\n",
    "start_time = \"15:00:00\"\n",
    "end_time   = \"15:59:59\"\n",
    "\n",
    "# Subsampling:\n",
    "# Option A: manual frame_step (ignored if target_max_samples is set and frame_step==1)\n",
    "frame_step = 1\n",
    "\n",
    "# Option B: automatic subsampling to aim for <= target_max_samples total frames\n",
    "target_max_samples = None   # None to disable auto-selection\n",
    "\n",
    "os.makedirs(trajectories_output_dir, exist_ok=True)\n",
    "os.makedirs(embeddings_output_dir, exist_ok=True)\n",
    "\n",
    "traj_csv_path = build_trajectories_csv(\n",
    "    folder=edinburgh_folder,\n",
    "    output_dir=trajectories_output_dir,\n",
    "    width=width,\n",
    "    height=height,\n",
    "    grayscale=grayscale,\n",
    "    start_time=start_time,\n",
    "    end_time=end_time,\n",
    "    use_all_times=use_all_times,\n",
    "    frame_step=frame_step,\n",
    "    target_max_samples=target_max_samples,\n",
    ")\n",
    "\n",
    "print(\"Trajectory CSV ready:\", traj_csv_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c980de",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(traj_csv_path)\n",
    "print(\"Full dataframe shape:\", df.shape)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c6d499",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_pixel_columns(df: pd.DataFrame):\n",
    "    pixel_cols = [c for c in df.columns if PIXEL_RE.match(c)]\n",
    "    if not pixel_cols:\n",
    "        raise SystemExit(\n",
    "            \"No pixel columns found. Expected columns like '1x1', '1x2', \"\n",
    "            \"'1x1_r', etc.\"\n",
    "        )\n",
    "    return pixel_cols\n",
    "\n",
    "\n",
    "# No random subsampling: df_sub is the full trajectory set produced\n",
    "df_sub = df.copy()\n",
    "\n",
    "pixel_cols = find_pixel_columns(df_sub)\n",
    "X = df_sub[pixel_cols].to_numpy(dtype=np.float32)\n",
    "\n",
    "print(\"Frames used for UMAP:\", len(df_sub))\n",
    "print(\"Pixel dim:\", X.shape[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd60b4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_quality_metrics(X_high, X_low, n_neighbors=15):\n",
    "    \"\"\"\n",
    "    Compute simple projection quality metrics:\n",
    "      - trustworthiness\n",
    "      - kNN overlap (Jaccard over neighbor sets)\n",
    "    \"\"\"\n",
    "    n_samples = X_high.shape[0]\n",
    "    if n_samples <= 1:\n",
    "        return {\"trustworthiness\": np.nan, \"knn_overlap\": np.nan}\n",
    "\n",
    "    k = min(n_neighbors, n_samples - 1)\n",
    "\n",
    "    # Trustworthiness (sklearn implementation)\n",
    "    tw = trustworthiness(X_high, X_low, n_neighbors=k)\n",
    "\n",
    "    # kNN overlap\n",
    "    nn_high = NearestNeighbors(n_neighbors=k + 1, metric=\"euclidean\").fit(X_high)\n",
    "    nn_low = NearestNeighbors(n_neighbors=k + 1, metric=\"euclidean\").fit(X_low)\n",
    "\n",
    "    _, idx_high = nn_high.kneighbors(X_high)\n",
    "    _, idx_low = nn_low.kneighbors(X_low)\n",
    "\n",
    "    overlaps = []\n",
    "    for i in range(n_samples):\n",
    "        hi = set(idx_high[i, 1:])  # drop self\n",
    "        lo = set(idx_low[i, 1:])\n",
    "        inter = len(hi & lo)\n",
    "        union = len(hi | lo)\n",
    "        if union > 0:\n",
    "            overlaps.append(inter / union)\n",
    "\n",
    "    knn_overlap = float(np.mean(overlaps)) if overlaps else np.nan\n",
    "\n",
    "    return {\n",
    "        \"trustworthiness\": float(tw),\n",
    "        \"knn_overlap\": knn_overlap,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee931970",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_embedding_filename(\n",
    "    output_dir,\n",
    "    traj_csv_path,\n",
    "    seed,\n",
    "    n_neighbors,\n",
    "    min_dist,\n",
    "    metric,\n",
    "    n_samples,\n",
    "):\n",
    "    \"\"\"\n",
    "    Create a unique filename for an embedding based on:\n",
    "    - base trajectory CSV\n",
    "    - sample count\n",
    "    - UMAP params\n",
    "    - seed\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    base_traj = os.path.splitext(os.path.basename(traj_csv_path))[0]\n",
    "    md_str = str(min_dist).replace(\".\", \"p\")\n",
    "    metric_str = metric.replace(\" \", \"_\")\n",
    "    name = (\n",
    "        f\"{base_traj}_samples{n_samples}_metric{metric_str}\"\n",
    "        f\"_nn{n_neighbors}_md{md_str}_seed{seed}.npy\"\n",
    "    )\n",
    "    return os.path.join(output_dir, name)\n",
    "\n",
    "\n",
    "def run_umap_grid(\n",
    "    X,\n",
    "    n_neighbors_list,\n",
    "    min_dist_list,\n",
    "    metric,\n",
    "    random_state,\n",
    "    quality_k,\n",
    "    traj_csv_path,\n",
    "    embeddings_dir,\n",
    "):\n",
    "    \"\"\"\n",
    "    Run UMAP for all (n_neighbors, min_dist) combinations.\n",
    "\n",
    "    For each combo:\n",
    "      - tries to load an existing embedding from disk (based on params + seed)\n",
    "      - otherwise runs UMAP, saves the embedding to .npy, and records metrics.\n",
    "\n",
    "    Returns:\n",
    "      - results_df: one row per combo with metrics\n",
    "      - embeddings: {(n_neighbors, min_dist) -> (N, 2) array}\n",
    "    \"\"\"\n",
    "    os.makedirs(embeddings_dir, exist_ok=True)\n",
    "\n",
    "    results = []\n",
    "    embeddings = {}\n",
    "    n_samples = X.shape[0]\n",
    "\n",
    "    for nn in n_neighbors_list:\n",
    "        for md in min_dist_list:\n",
    "            emb_path = make_embedding_filename(\n",
    "                output_dir=embeddings_dir,\n",
    "                traj_csv_path=traj_csv_path,\n",
    "                seed=random_state,\n",
    "                n_neighbors=nn,\n",
    "                min_dist=md,\n",
    "                metric=metric,\n",
    "                n_samples=n_samples,\n",
    "            )\n",
    "\n",
    "            if os.path.exists(emb_path):\n",
    "                print(f\"[CACHE] Loading embedding from {emb_path}\")\n",
    "                emb = np.load(emb_path)\n",
    "            else:\n",
    "                print(f\"[UMAP] n_neighbors={nn}, min_dist={md} (seed={random_state})\")\n",
    "                reducer = umap.UMAP(\n",
    "                    n_neighbors=nn,\n",
    "                    min_dist=md,\n",
    "                    metric=metric,\n",
    "                    n_components=2,\n",
    "                    random_state=random_state,\n",
    "                )\n",
    "                emb = reducer.fit_transform(X)\n",
    "                np.save(emb_path, emb)\n",
    "                print(f\"[SAVE] Stored embedding to {emb_path}\")\n",
    "\n",
    "            metrics = compute_quality_metrics(X, emb, n_neighbors=quality_k)\n",
    "\n",
    "            embeddings[(nn, md)] = emb\n",
    "            row = {\n",
    "                \"n_neighbors\": nn,\n",
    "                \"min_dist\": md,\n",
    "                \"metric\": metric,\n",
    "                \"seed\": random_state,\n",
    "                \"trustworthiness\": metrics[\"trustworthiness\"],\n",
    "                \"knn_overlap\": metrics[\"knn_overlap\"],\n",
    "                \"embedding_path\": emb_path,\n",
    "            }\n",
    "            results.append(row)\n",
    "\n",
    "    results_df = pd.DataFrame(results)\n",
    "    return results_df, embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e1bab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the hyperparameter grid\n",
    "n_neighbors_list = [5, 15, 50]\n",
    "min_dist_list    = [0.0, 0.1, 0.5]\n",
    "\n",
    "metric    = \"euclidean\"\n",
    "quality_k = 15\n",
    "\n",
    "results_df, embeddings = run_umap_grid(\n",
    "    X,\n",
    "    n_neighbors_list=n_neighbors_list,\n",
    "    min_dist_list=min_dist_list,\n",
    "    metric=metric,\n",
    "    random_state=SEED,\n",
    "    quality_k=quality_k,\n",
    "    traj_csv_path=traj_csv_path,\n",
    "    embeddings_dir=embeddings_output_dir,\n",
    ")\n",
    "\n",
    "# Sort by trustworthiness (descending) for quick inspection\n",
    "results_df_sorted = results_df.sort_values(\"trustworthiness\", ascending=False)\n",
    "results_df_sorted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba3f5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_embedding_grid(\n",
    "    df_sub,\n",
    "    embeddings,\n",
    "    results_df,\n",
    "    n_neighbors_list,\n",
    "    min_dist_list,\n",
    "    figsize_scale=4,\n",
    "    plot_path=None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Create a grid of scatterplots:\n",
    "    rows   = different n_neighbors\n",
    "    columns= different min_dist\n",
    "    \"\"\"\n",
    "    if \"line\" not in df_sub.columns:\n",
    "        raise SystemExit(\"Column 'line' not found in dataframe; needed for coloring.\")\n",
    "\n",
    "    cat = pd.Categorical(df_sub[\"line\"])\n",
    "    codes = cat.codes  # 0..K-1\n",
    "\n",
    "    n_rows = len(n_neighbors_list)\n",
    "    n_cols = len(min_dist_list)\n",
    "\n",
    "    fig, axes = plt.subplots(\n",
    "        n_rows,\n",
    "        n_cols,\n",
    "        figsize=(figsize_scale * n_cols, figsize_scale * n_rows),\n",
    "        squeeze=False,\n",
    "    )\n",
    "\n",
    "    for i, nn in enumerate(n_neighbors_list):\n",
    "        for j, md in enumerate(min_dist_list):\n",
    "            ax = axes[i, j]\n",
    "            key = (nn, md)\n",
    "            if key not in embeddings:\n",
    "                ax.axis(\"off\")\n",
    "                continue\n",
    "\n",
    "            emb = embeddings[key]\n",
    "            sc = ax.scatter(\n",
    "                emb[:, 0],\n",
    "                emb[:, 1],\n",
    "                c=codes,\n",
    "                s=3,\n",
    "                alpha=0.7,\n",
    "                cmap=\"tab20\",\n",
    "            )\n",
    "            ax.set_xticks([])\n",
    "            ax.set_yticks([])\n",
    "\n",
    "            match = results_df[\n",
    "                (results_df[\"n_neighbors\"] == nn)\n",
    "                & (results_df[\"min_dist\"] == md)\n",
    "            ]\n",
    "            if not match.empty:\n",
    "                row = match.iloc[0]\n",
    "                title = (\n",
    "                    f\"nn={nn}, md={md}\\n\"\n",
    "                    f\"trust={row['trustworthiness']:.3f}, \"\n",
    "                    f\"kNNov={row['knn_overlap']:.3f}\"\n",
    "                )\n",
    "            else:\n",
    "                title = f\"nn={nn}, md={md}\"\n",
    "            ax.set_title(title, fontsize=9)\n",
    "\n",
    "    fig.tight_layout()\n",
    "\n",
    "    if plot_path is not None:\n",
    "        fig.savefig(plot_path, dpi=300)\n",
    "\n",
    "    return fig\n",
    "\n",
    "\n",
    "base_traj = os.path.splitext(os.path.basename(traj_csv_path))[0]\n",
    "grid_plot_path = os.path.join(\n",
    "    embeddings_output_dir,\n",
    "    f\"{base_traj}_umap_grid_seed{SEED}.png\",\n",
    ")\n",
    "\n",
    "fig = plot_embedding_grid(\n",
    "    df_sub=df_sub,\n",
    "    embeddings=embeddings,\n",
    "    results_df=results_df,\n",
    "    n_neighbors_list=n_neighbors_list,\n",
    "    min_dist_list=min_dist_list,\n",
    "    figsize_scale=4,\n",
    "    plot_path=grid_plot_path,\n",
    ")\n",
    "\n",
    "print(\"Saved grid plot to:\", grid_plot_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9e3628",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save ALL UMAP configs as CSV + per-config PNG scatterplots\n",
    "# Names encode: trajectory CSV, sample count, metric, n_neighbors, min_dist, seed\n",
    "\n",
    "n_samples = X.shape[0]\n",
    "\n",
    "if \"line\" not in df_sub.columns:\n",
    "    raise SystemExit(\"Column 'line' not found in df_sub; needed for coloring.\")\n",
    "\n",
    "cat = pd.Categorical(df_sub[\"line\"])\n",
    "codes = cat.codes  # 0..K-1\n",
    "\n",
    "saved_count = 0\n",
    "\n",
    "for (nn, md), emb in embeddings.items():\n",
    "    # Reconstruct the embedding base filename (same as used in run_umap_grid)\n",
    "    emb_path = make_embedding_filename(\n",
    "        output_dir=embeddings_output_dir,\n",
    "        traj_csv_path=traj_csv_path,\n",
    "        seed=SEED,\n",
    "        n_neighbors=nn,\n",
    "        min_dist=md,\n",
    "        metric=metric,\n",
    "        n_samples=n_samples,\n",
    "    )\n",
    "\n",
    "    csv_path = emb_path.replace(\".npy\", \".csv\")\n",
    "    png_path = emb_path.replace(\".npy\", \".png\")\n",
    "\n",
    "    # 1) Save CSV with x,y attached\n",
    "    df_emb = df_sub.copy()\n",
    "    df_emb[\"x\"] = emb[:, 0]\n",
    "    df_emb[\"y\"] = emb[:, 1]\n",
    "    df_emb.to_csv(csv_path, index=False)\n",
    "\n",
    "    # 2) Save per-config scatterplot\n",
    "    fig, ax = plt.subplots(figsize=(6, 5))\n",
    "    sc = ax.scatter(\n",
    "        emb[:, 0],\n",
    "        emb[:, 1],\n",
    "        c=codes,\n",
    "        s=3,\n",
    "        alpha=0.7,\n",
    "        cmap=\"tab20\",\n",
    "    )\n",
    "    ax.set_xlabel(\"x (UMAP)\")\n",
    "    ax.set_ylabel(\"y (UMAP)\")\n",
    "\n",
    "    row = results_df[\n",
    "        (results_df[\"n_neighbors\"] == nn)\n",
    "        & (results_df[\"min_dist\"] == md)\n",
    "    ]\n",
    "    if not row.empty:\n",
    "        r = row.iloc[0]\n",
    "        title = (\n",
    "            f\"nn={nn}, md={md}, seed={int(r['seed'])}\\n\"\n",
    "            f\"trust={r['trustworthiness']:.3f}, \"\n",
    "            f\"kNNov={r['knn_overlap']:.3f}\"\n",
    "        )\n",
    "    else:\n",
    "        title = f\"nn={nn}, md={md}, seed={SEED}\"\n",
    "    ax.set_title(title, fontsize=9)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    fig.savefig(png_path, dpi=300)\n",
    "    plt.close(fig)\n",
    "\n",
    "    saved_count += 1\n",
    "\n",
    "print(\n",
    "    f\"Saved CSV + PNG for {saved_count} UMAP configurations in '{embeddings_output_dir}'.\"\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
